---
title: "Bioconductor tools for mass spectrometry and proteomics"
author:
- name: Laurent Gatto
  affiliation: "de Duve Institute, UCLouvain, Belgium"
output:
  BiocStyle::html_document:
    toc_float: true
---


<style type="text/css">
/* https://jsfiddle.net/2ffd2qgo/ */
.boxed {
  float: right;
  padding: 0 2px 0 2px;
  border: 1px solid rgba(0, 0, 0, .2);
  border-radius: 4px;
  margin-left: 2px;
  margin-right: 2px;
}

.blue {
  background: #13b4ff;
}

.purple {
  background: #ab3fdd;
}

.wine {
  background: #ae163e;
}

.yellow {
  background: #ffff09;
}
</style>

<!-- <div class="boxed blue">Beginner</div> -->
<!-- <div class="boxed purple">Foo</div> -->
<!-- <div class="boxed yellow">On-line</div> -->
<!-- <div class="boxed wine">Hello</div><br/> -->


```{r env, echo=FALSE, message=FALSE, warning=FALSE}
.cache <- FALSE
stopifnot(packageVersion("BiocStyle") >= "2.5.19")
suppressPackageStartupMessages(library("BiocStyle"))
suppressPackageStartupMessages(library("MSnbase"))
suppressPackageStartupMessages(library("BiocParallel"))
suppressPackageStartupMessages(library("BiocInstaller"))
suppressPackageStartupMessages(library("RforProteomics"))
suppressPackageStartupMessages(library("lattice"))
suppressPackageStartupMessages(library("gridExtra"))
suppressPackageStartupMessages(library("pRoloc"))
suppressPackageStartupMessages(library("AnnotationHub"))
suppressPackageStartupMessages(library("ensembldb"))
```

<!-- **Modified:** `r file.info("lab.Rmd")$mtime`<br /> -->
<!-- **Compiled**: `r date()` -->


**Abstract** In this course, we will use R/Bioconductor packages to
explore, process, visualise and understand mass spectrometry-based
proteomics data, starting with raw data, and proceeding with
identification and quantitation data, discussing some of their
peculiarities compared to sequencing data along the way. The workflow
is aimed at a beginner to intermediate level, such as, for example,
seasoned R users who want to get started with mass spectrometry and
proteomics, or proteomics practitioners who want to familiarise
themselves with R and Bioconductor infrastructure.

----

This material available under a [**creative common
CC-BY**](http://creativecommons.org/licenses/by/4.0/) license. You are
free to **share** (copy and redistribute the material in any medium or
format) and **adapt** (remix, transform, and build upon the material)
for any purpose, even commercially.

If you (re-)use this material, please cite the following reference

> Gatto, Laurent. (2019, January). Bioconductor tools for mass
> spectrometry and
> proteomics. Zenodo. http://doi.org/10.5281/zenodo.2547971

# Introduction

Before we start:

> If you identify typos, if there are parts that you would like to see
> expended or clarified, please let me know by telling me directly
> (during workshops), opening a [github
> issue](https://github.com/lgatto/bioc-ms-prot/issues) or by emailing
> me. Please do also briefly specify your background/familiarity with
> mass spectrometry and/or proteomics (beginner, intermediate or
> expert) so that I can update accordingly.

In recent years, there we have seen an increase in the number of
packages to analyse mass spectrometry and proteomics data for R and
Bioconductor, as well as an increase in total number of downloads. See
vignette [Proteomics packages in
Bioconductor](https://lgatto.github.io/RforProteomics/articles/biocprot.html)
for more details and code underlying these figures.

![Number of packages](./Figures/nbpkgs-1.png)
![Number of downloads](./Figures/nnbdown-1.png)



It is also good to highlight that several of these package have become
a group efforts, supported by several developers in the
community. This [post](https://lgatto.github.io/msnbase-contribs/)
illustrates the various contributions to `r Biocpkg("MSnbase")`.
`r Biocpkg("mzR")` has benefited by a similar wide range of successful
contributions. Both packages, and in particular `r Biocpkg("mzR")`,
are used by many others, and will be described in some detail in this
workflow.

This workflow illustrates R / Bioconductor infrastructure for
proteomics. Topics covered focus on support for open community-driven
formats for raw data and identification results, packages for
peptide-spectrum matching, data processing and analysis:

- Exploring available infrastructure
- Mass spectrometry data
- Getting data from proteomics repositories
- Handling raw MS data
- Handling identification data
- MS/MS database search
- Analysing search results
- High-level data interface
- Quantitative proteomics
- Importing third-party quantitation data
- Data processing and analysis
- Statistical analysis
- Machine learning
- Annotation
- Other relevant packages/pipelines

Links to other packages and references are also documented. In
particular, the vignettes included in the
`r Biocannopkg("RforProteomics")`
package also contains relevant material.

### Other material {-}

This workflow provides a *general* introduction to Bioconductor software
for mass spectrometry and proteomics. If you are interested in

- The application of machine learning to proteomics data, in particular
  spatial proteomics (i.e. the sub-cellular localisation), follow the
  tutorial vignette from `r Biocpkg("pRoloc")` package, accessible
  with `vignette("pRoloc-tutorial", package = "pRoloc")` or
  [online](https://lgatto.github.io/pRoloc/).
- The analysis of identification data to retain the most reliable
  PSMs, see the `r Biocpkg("MSnID")`
  vignette^[Section *Analysing search results* below is a summary of that vignette.],
  accessible with `vignette("msnid_vignette", package = "MSnID")` or
  [online](https://bioconductor.org/packages/release/bioc/vignettes/MSnID/inst/doc/msnid_vignette.pdf). In
  addition, the vignettes of the `r Biocpkg("msmsTest")` package
  describe how to analyse spectral counting data using packages
  dedicated for the analysis of high throughput sequencing data.
- The analysis of MS^E^ data independent acquisition (DIA), see the
  vignettes in the `r Biocpkg("synapter")` package.
- The processing and analysis of MALDI-MS data, read the
  `r CRANpkg("MALDIquant")` introduction accessible with
  `vignette("MALDIquant-intro", package = "MALDIquant")` and available
  [online](https://cran.r-project.org/web/packages/MALDIquant/).
- The processing and analysis of imaging mass spectrometry (IMS), read
  the `r Biocpkg("Carinal")` walkthrough vignette accessible
  with `vignette("Cardinal-walkthrough", package = "Cardinal")` and
  [online](https://bioconductor.org/packages/release/bioc/vignettes/Cardinal/inst/doc/Cardinal-walkthrough.pdf).
- ...

## Setup { - }

The follow packages will be used throughout this documents. R version
`3.5` or higher is required to install all the packages using
`BiocManager::install`.

```{r setup, message=FALSE, echo=TRUE, warning=FALSE}
library("mzR")
library("mzID")
library("MSnID")
library("MSnbase")
library("rpx")
library("MLInterfaces")
library("pRoloc")
library("pRolocdata")
library("MSGFplus")
library("rols")
library("hpar")
library("ensembldb")
```

The most convenient way to install most of the tutorials requirement (and
more related content), is to install `r Biocannopkg("RforProteomics")`
with all its dependencies.

```{r r4pinstall, eval=FALSE}
if (!require("BiocManager"))
    install.package("BiocManager")
BiocManager::install("RforProteomics", dependencies = TRUE)
```

Other packages of interest, such as
`r Biocpkg("rTANDEM")` or `r Biocpkg("MSGFgui")`
will be described later in the document but are not required to
execute the code in this workflow.

<!-- To study the workflow off-line, it is possible to download data files -->
<!-- as a package in advance^[See details in the *Data packages* -->
<!-- section.]. Install the dependencies and the package prior to the -->
<!-- workshop with -->

<!-- ```{r pxd1pkg0, eval = FALSE} -->
<!-- BiocManager::install(c("msdata", "MSnbase", "mzR")) -->
<!-- BiocManager::install("lgatto/PXD000001") -->
<!-- ``` -->

## Exploring available infrastructure { - }

<div class="boxed yellow">On-line</div>

```{r pk, echo=FALSE, warning=FALSE, cache=TRUE}
biocv <- as.character(biocVersion())
pp <- proteomicsPackages(biocv)
msp <- massSpectrometryPackages(biocv)
msdp <- massSpectrometryDataPackages(biocv)
```

In Bioconductor version `r biocv`, there are respectively `r nrow(pp)`
[proteomics](http://bioconductor.org/packages/release/BiocViews.html#___Proteomics),
`r nrow(msp)`
[mass spectrometry software packages](http://bioconductor.org/packages/release/BiocViews.html#___MassSpectrometry)
and `r nrow(msdp)`
[mass spectrometry experiment packages](http://bioconductor.org/packages/release/BiocViews.html#___MassSpectrometryData). These
respective packages can be extracted with the `proteomicsPackages()`,
`massSpectrometryPackages()` and `massSpectrometryDataPackages()` and
explored interactively, or looked at by exploring the respective
`biocViews` on the
[Bioconductor web page](https://bioconductor.org/packages/release/BiocViews.html#___Software).


```{r pp, eval = TRUE, warning = FALSE, fig.cap = "Exploring proteomics packages"}
library("RforProteomics")
pp <- proteomicsPackages()
DT::datatable(pp)
```

> **Exercise** Explore available proteomics packages using the
> `proteomicsPackages()` function above or the [Bioconductor software
> page](https://bioconductor.org/packages/release/BiocViews.html#___Software). What
> software could you use to analyse `mzML` files?

## Mass spectrometry data { - }

Most community-driven formats described in the table are supported in
`R`. We will see how to read and access these data in the following
sections.

```{r datatab, results='asis', echo=FALSE}
datatab <-
    data.frame(Type = c("raw", "identification", "quantitation",
                   "peak lists", "quant and id"),
               Format = c("mzML, mzXML, netCDF, mzData",
                   "mzIdentML", "mzQuantML", "mgf", "mzTab"),
               Package = c(
                   "*[MSnbase](http://bioconductor.org/packages/MSnbase)* (read and write in version >= 2.3.13) via *[mzR](http://bioconductor.org/packages/mzR)*",
                   paste("*[mzID](http://bioconductor.org/packages/mzID)* (read) and",
                         "*[MSnbase](http://bioconductor.org/packages/MSnbase)* (read, via *[mzR](http://bioconductor.org/packages/mzR)*)"),
                   "",
                   "*[MSnbase](http://bioconductor.org/packages/MSnbase)* (read)",
                   "*[MSnbase](http://bioconductor.org/packages/MSnbase)* (read)"))

knitr::kable(datatab)
```

# How does mass spectrometry work?

Mass spectrometry (MS) is a technology that *separates* charged
molecules (ions) based on their mass to charge ratio (M/Z). It is
often coupled to chromatography (liquid LC, but can also be gas-based
GC). The time an analytes takes to elute from the chromatography
column is the *retention time*.

![A chromatogram, illustrating the total amount of analytes over the retention time.](./Figures/chromatogram.png)

An mass spectrometer is composed of three components:

1. The *source*, that ionises the molecules: examples are Matrix-assisted
   laser desorption/ionisation (MALDI) or electrospray ionisation.
   (ESI)
2. The *analyser*, that separates the ions: Time of flight (TOF) or Orbitrap.
3. The *detector* that quantifies the ions.

When using mass spectrometry for proteomics, the proteins are first
digested with a protease such as trypsin. In mass shotgun proteomics,
the analytes assayed in the mass spectrometer are peptides.

Often, ions are subjected to more than a single MS round. After a
first round of separation, the peaks in the spectra, called MS1
spectra, represent peptides. At this stage, the only information we
possess about these peptides are their retention time and their
mass-to-charge (we can also infer their charge be inspecting their
isotopic envelope, i.e the peaks of the individual isotopes, see
below), which is not enough to infer their identify (i.e. their
sequence).

In MSMS (or MS2), the settings of the mass spectrometer are set
automatically to select a certain number of MS1 peaks (for example
20). Once a narrow M/Z range has been selected (corresponding to one
high-intensity peak, a peptide, and some background noise), it is
fragmented (using for example collision-induced dissociation (CID),
higher energy collisional dissociation (HCD) or electron-transfer
dissociation (ETD)). The fragment ions are then themselves separated
in the analyser to produce a MS2 spectrum. The unique fragment ion
pattern can then be used to infer the peptide sequence using de novo
sequencing (when the spectrum is of high enough quality) of using a
search engine such as, for example Mascot, MSGF+, ..., that will match
the observed, experimental spectrum to theoratical spectra (see
details below).

![Schematics of a mass spectrometer and two rounds of MS.](./Figures/SchematicMS2.png)

The animation below show how 25 ions different ions (i.e. having
different M/Z values) are separated throughout the MS analysis and are
eventually detected (i.e. quantified). The final frame shows the
hypothetical spectrum.

```{r mstut0, echo=FALSE}
if (!file.exists("Figures/mstut.gif")) {
    library("mstut")
    library("animation")
    set.seed(1L)
    x <- new_ions(npeaks = 25, nimg = 10)
    saveGIF({
        analyse(x, sleep = 0)
        detect(x)
        spectrum(x, main = "Spectrum")
    }, movie.name = "./Figures/mstut.gif")
}
```

![Separation and detection of ions in a mass spectrometer.](./Figures/mstut.gif)

The figures below illustrate the two rounds of MS. The spectrum on the
left is an MS1 spectrum acquired after 21 minutes and 3 seconds of
elution. 10 peaks, highlited by dotted vertical lines, were selected
for MS2 analysis. The peak at M/Z 460.79 (488.8) is highlighted by a
red (orange) vertical line on the MS1 spectrum and the fragment
spectra are shown on the MS2 spectrum on the top (bottom) right
figure.

![Parent ions in the MS1 spectrum (left) and two sected fragment ions MS2 spectra (right).](./Figures/MS1-MS2-spectra.png)

The figures below represent the 3 dimensions of MS data: a set of
spectra (M/Z and intensity) of retention time, as well as the
interleaved nature of MS1 and MS2 (and there could be more levels)
data.

![MS1 spectra over retention time.](./Figures/F02-3D-MS1-scans-400-1200-lattice.png)

![MS2 spectra interleaved between two MS1 spectra.](./Figures/F02-3D-MS1-MS2-scans-100-1200-lattice.png)

# Accessing data

## From the ProteomeXchange database

<div class="boxed yellow">On-line</div>

MS-based proteomics data is disseminated through the
[ProteomeXchange](http://www.proteomexchange.org/) infrastructure,
which centrally coordinates submission, storage and dissemination
through multiple data repositories, such as the
[PRoteomics IDEntifications (PRIDE)](https://www.ebi.ac.uk/pride/archive/)
database at the EBI for mass spectrometry-based experiments (including
quantitative data, as opposed as the name suggests),
[PASSEL](http://www.peptideatlas.org/passel/) at the ISB for Selected
Reaction Monitoring (SRM, i.e. targeted) data and the
[MassIVE](http://massive.ucsd.edu/ProteoSAFe/static/massive.jsp)
resource. These data can be downloaded within R using the
`r Biocpkg("rpx")` package.


```{r rpx}
library("rpx")
pxannounced()
```

Using the unique `PXD000001` identifier, we can retrieve the relevant
metadata that will be stored in a `PXDataset` object. The names of the
files available in this data can be retrieved with the `pxfiles`
accessor function.

```{r pxd}
px <- PXDataset("PXD000001")
px
pxfiles(px)
```

Other metadata for the `px` data set:

```{r pxvar}
pxtax(px)
pxurl(px)
pxref(px)
```

Data files can then be downloaded with the `pxget` function. Below, we
retrieve the raw data file. The file is
downloaded^[If the file is already available, it is not downloaded a second time.]
in the working directory and the name of the file is return by the
function and stored in the `mzf` variable for later use ^[This and other files are also availabel in the `msdata` package, described below].

```{r pxget}
fn <- "TMT_Erwinia_1uLSike_Top10HCD_isol2_45stepped_60min_01-20141210.mzML"
mzf <- pxget(px, fn)
mzf
```


## From AnnotationHub

<div class="boxed yellow">On-line</div>

`r Biocpkg("AnnotationHub")` is a cloud resource set up and managed by
the Bioconductor project that serves various omics datasets. It is
possible to contribute and access (albeit currently only a limited
number of)
[proteomics data](http://bioconductor.org/packages/devel/bioc/vignettes/ProteomicsAnnotationHubData/inst/doc/ProteomicsAnnotationHubData.html).

```{r ah0}
library("AnnotationHub")
ah <- AnnotationHub()
query(ah, "proteomics")
```

```{r ah, message=FALSE}
ms <- ah[["AH49008"]]
ms
```

```{r mshd, echo=FALSE}
lms <- length(ms)
hd <- header(ms)
nms1 <- table(hd$msLevel)[[1]]
nms2 <- table(hd$msLevel)[[2]]
```

The data contains `r lms` spectra - `r nms1` MS1 spectra and `r nms2`
MS2 spectra. The file name, `r basename(fileName(ms))`, is not very
descriptive because the data originates from the `AnnotationHub` cloud
repository. If the data was read from a local file, is would be named
as the `mzML` (or `mzXML`) file (see below).

## Data packages

Some data are also distributed through dedicated packages. The
`r BiocStyle::Biocexptpkg("msdata")`, for example, provides some
general raw data files relevant for both proteomics and
metabolomics.

```{r msdatafiles}
library("msdata")
## proteomics raw data
proteomics()
## proteomics identification data
ident()
```

More often, such *experiment packages* distribute processed data; an
example of such is the `r BiocStyle::Biocexptpkg("pRolocdata")`
package, that offers quantitative proteomics data.

<!-- The files from the *PXD00001* experiment are also available in the -->
<!-- `r Githubpkg("lgatto/PXD000001")`. This option is convenient when -->
<!-- online access is absent or unreliable. Install the dependencies and -->
<!-- the package prior to the workshop with -->

<!-- ```{r pxd1pkg, eval = FALSE} -->
<!-- library("BiocInstaller") -->
<!-- BiocManager::install(c("msdata", "MSnbase", "mzR")) -->
<!-- BiocManager::install("lgatto/PXD0001") -->
<!-- ``` -->

<!-- The `r Githubpkg("lgatto/PXD000001")` packages provides the `px1files` -->
<!-- and `px1get` functions as a drop-in replacement for the `pxfiles` and -->
<!-- `pxget` function from `r Biocpkg("rpx")` package, for the *PXD000001* -->
<!-- dataset. -->

<!-- ```{r unlinkfas, echo=FALSE} -->
<!-- unlink("erwinia_carotovora.fasta") -->
<!-- ``` -->

<!-- ```{r pxd1pkg2} -->
<!-- library("PXD000001") -->
<!-- px1files() -->
<!-- px1get("erwinia_carotovora.fasta") -->
<!-- ``` -->

# Raw MS data

## High-level data structures

The `r Biocpkg("MSnbase")` package provides high-level data
abstractions for raw MS data through the `MSnExp` class and containers
for quantification data via the `MSnSet` class (see *Quantitative
proteomics* section). Both store

1. the actual assay data (spectra or quantitation matrix, see below),
   accessed with `spectra` (or the `[`, `[[` operators) or `exprs`;
2. sample metadata, accessed as a `data.frame` with `pData`;
3. feature metadata, accessed as a `data.frame` with `fData`.

Another useful slot is `processingData`, accessed with
`processingData(.)`, that records all the processing that objects have
undergone since their creation (see examples below).

## Raw data: the `MSnExp` class

### Read raw data {-}

The `readMSData` will parse the raw data and construct an MS
experiment object of class `MSnExp`. An important argument to
`readMSData` is the *mode*, which can be `"onDisk"` or
`"inMemory"`. The former doesn't load the raw data in memory (which is
not advised for MS1 data, or when many files are loaded) and is
generally the recommended mode. See the *benchmarking* vignette^[Open
it with `vignette("benchmarking", package = "MSnbase")` or read it
[online](https://bioconductor.org/packages/release/bioc/vignettes/MSnbase/inst/doc/benchmarking.html)]
for details).

```{r msnbase}
library("MSnbase")
## get a small test data
rawFile <- dir(system.file(package = "MSnbase",
                           dir = "extdata"),
               full.name = TRUE,
               pattern = "mzXML$")
basename(rawFile)
msexp <- readMSData(rawFile, msLevel = 2L)
msexp
```

Spectra can be extracted as a list of `Spectrum2` objects with the
`spectra` accessor or as a subset of the original `MSnExp` data with
the `[` operator.  Individual spectra can be accessed with `[[`.

```{r msnb2}
length(msexp)
msexp[1:2]
msexp[[2]]
```

### Chromatograms {-}

We can also extract the chromatogram for the acquistion(s) in the
`MSnExp` object and visualise it. Here, we use a complete acquisition
from the `msdata` package, and read it with *on-disk* mode and focus
on MS1 data, which is used to generate chromatograms.

```{r chrom1, cache = TRUE, fig.caption = "Chromatogram of TMT_Erwinia_1uLSike_Top10HCD_isol2_45stepped_60min_01-20141210.mzML."}
f <- msdata::proteomics(pattern = "45stepped_60min_01-20141210", full.names = TRUE)
rw <- readMSData(f, mode = "onDisk", msLevel. = 1L)
chr <- chromatogram(rw)
chr
plot(chr)
```

Note that here, as we only loaded a single raw data file, we obtain a
`Chromatograms` object with a single chromatogram. When reading
multiple raw data files at once (for example with
`readMSData(c("f1.mzML", "f2.mzML"))`), we would get and visualise one
chromatogram per file.

### Annotating spectra with identification results {-}

The identification results stemming from the same raw data file can
then be used to add PSM matches. Here, we use the small `msexp` test
data with 5 MS2 spectra that we read in further up.

```{r addid}
## initial feature variable
fData(msexp)
## find path to a mzIdentML file
identFile <- dir(system.file(package = "MSnbase", dir = "extdata"),
                 full.name = TRUE, pattern = "dummyiTRAQ.mzid")
basename(identFile)
msexp <- addIdentificationData(msexp, identFile)
## additional feature variables
fvarLabels(msexp)
```

We see that 3 out of 5 MS2 spectra in the `msexp` data have been
identified; those that haven't have missing values for the new,
id-related feature variables.

```{r checkid}
fData(msexp)$rank
fData(msexp)$isDecoy
```

> **Exercise** Load all MS level data from file `MS3TMT11.mzML`
> available in the `msdata` package using `readMSData`, making sure
> you set `mode = "onDisk"`, and verify which MS levels (accessible
> with the `msLevel` function) are centroided (accessible with the
> `centroided()` function). See section *Raw data processing* for data
> in profile and centroided (processed) modes.

<details>
```{r answ3}
f <- proteomics(full.names = TRUE, pattern = "MS3TMT11.mzML")
ms <- readMSData(f, mode = "onDisk")
table(centroided(ms), msLevel(ms))
```
</details>

### Plotting MS spectra {-}

Spectra and (parts of) experiments can be extracted and plotted.

```{r specplot, fig.cap="Plotting an object of class `Spectrum`."}
msexp[[1]]
plot(msexp[[1]])
```

As this data was labeled with iTRAQ4 isobaric tags, we can highlight
these four peaks of interest on top of the full spectrum with

```{r specplot1, fig.cap="Plotting an object of class `Spectrum` with reporter ions."}
plot(msexp[[1]], full=TRUE, reporters = iTRAQ4)
```

```{r specplot2, fig.cap = "Plotting an object of class `MSnExp`"}
msexp[1:3]
plot(msexp[1:3], full = TRUE)
```

In the examples above, we only used a single file as input to
`readMSData`, but multiple file can be read into a single `MSnExp`
object. The origin of the spectra can be accessed with the `fromFile`
function:

```{r fromfiles}
fromFile(msexp)
```

> **Exercise** Repeat the previous combination of raw and
> identification data with the
> `TMT_Erwinia_1uLSike_Top10HCD_isol2_45stepped_60min_01-20141210.mzML.gz`
> and
> `TMT_Erwinia_1uLSike_Top10HCD_isol2_45stepped_60min_01-20141210.mzid`
> files from `msdata`. Retain only MS 2 level data; this can be done
> either when reading the data in (see the `msLevel` argument in
> `?readMSData`) or can be done afterwards by filtering the MS levels
> with `filterMsLevel`.

<details>
```{r answ5, cache=FALSE}
## read raw data
rwf <- proteomics(pattern = "TMT_Erwinia_1uLSike_Top10HCD_isol2_45stepped_60min_01-20141210.mzML.gz",
                  full.names = TRUE)
tmterw <- readMSData(rwf, mode = "onDisk")
## or, only read MS2-leve data
## tmterw <- readMSData(rwf, mode = "onDisk", msLevel = 2L)

## add identification data
idf <- ident(full.names = TRUE)
tmterw <- addIdentificationData(tmterw, idf)

tmterw2 <- filterMsLevel(tmterw, 2L)
```

```{r answ5b, eval=FALSE}
## It is also possible to chain operations
library("magrittr")
tmterw2 <- rwf %>%
    readMSData(mode = "onDisk") %>%
    addIdentificationData(idf) %>%
    filterMsLevel(2L)
```
</details>


> **Exercise** Still using the
> `TMT_Erwinia_1uLSike_Top10HCD_isol2_45stepped_60min_01-20141210`
> data from the previous exercise, identify the index of the MS2
> spectrum with the highest precursor intensity (see the
> `precursorIntensity` feature variable) and plot it as illustrated
> above.

<details>
```{r answ1}
i <- which.max(precursorIntensity(tmterw2))
sp <- tmterw2[[i]]
plot(sp, full = TRUE)
```
</details>

## Relations between scans

As seen in the introduction, scans have a hierarchical structure: MS2
spectra stem form a precursor MS1 scan. This also holds for MS3
spectra, that are the result from an additional analysis round of MS2
spectra. When validating quantitative or identification data by
referring back to raw data, it is often useful to be able to navigate
this structure.

We will use an experiment with 3 MS levels to do this:

```{r ms3}
ms3f <- proteomics(pattern = "MS3TMT11", full.names = TRUE)
basename(ms3f)
ms3 <- readMSData(ms3f, mode = "onDisk")
```

Note that it is important to use *on-disk* mode here, as we want to
retain all MS levels, which isn't possible with *in-memory* mode.

> **Exercise** Generate a table showing how many MS1, 2, and 3 level
> scans are available in this data

<details>
```{r ms3ex}
table(msLevel(ms3))
```
</details>


The `filterPrecursorScan` function takes on raw data object, it's
acquisition number (get them with `acquisitionNum`), and returns a new
raw data object containing the children of that spectrum.

> **Exercise** Find the acquisition of the first MS1 spectrum and
> extract all spectra that originate, directly and indirectly, from
> it.

<details>
```{r ms3prec}
head(msLevel(ms3))
head(acquisitionNum(ms3))
(from1 <- filterPrecursorScan(ms3, 21945))
msLevel(from1)
```
</details>

## Low-level access to raw data

<div class="boxed blue">Devel</div>

This section illustrates the underlying infrastructure from the `mzR`
package, that is used by `MSnbase` under the hood. It is recommended
to use the high level interfaces, as it supports multiple files and
does data integrity checks throughout data processing.

The `mzR` package provides an interface to the
[proteowizard](http://proteowizard.sourceforge.net/) C/C++ code base
to access various raw data files, such as `mzML`, `mzXML`, `netCDF`,
and `mzData`. The data is accessed on-disk, i.e it is not loaded
entirely in memory, and only when explicitly requested. The three main
functions are `openMSfile` to create a file handle to a raw data file,
`header` to extract metadata about the spectra contained in the file
and `peaks` to extract one or multiple spectra of interest. Other
functions such as `instrumentInfo`, or `runInfo` can be used to gather
general information about a run.

Below, we access the raw data file downloaded in the previous section
and open a file handle that will allow us to extract data and metadata
of interest.

```{r rawms}
library("mzR")
basename(mzf)
ms <- openMSfile(mzf)
ms
```

The object loaded from *AnnotationHub* in the previous section is of
the same type, and was also created by the `openMSfile` function. All
operations below can equally be applied to it.

The `header` function returns the metadata of all available peaks:

```{r hd}
hd <- header(ms)
dim(hd)
names(hd)
```

We can extract metadata and scan data for scan 1000 as follows:

```{r hdpeaks, fig.cap="Manual extraction and plotting of an MS spectrum"}
hd[1000, ]
head(peaks(ms, 1000))
plot(peaks(ms, 1000), type = "h", xlab = "M/Z", ylab = "Intensity")
```

See also this short [video](https://youtu.be/KwCRV885Z-k).

In general, it is highly advised to use the high-level interface
`MSnExp` provided by `MSnbase` to access and manipulate raw data for
the following reasons:

- it provides easy and safe accessor and filtering functions;
- it is compatible to data processing;
- it handles multiple files/acquisitions;
- it uses cached on-disk access and is as fast as the low-level
  interface.

## A bit more raw data visualisation

Below, we illustrate some additional visualisation and animations of
raw MS data, taken from the `r Biocannopkg("RforProteomics")`
[visualisation
vignette](http://bioconductor.org/packages/release/data/experiment/vignettes/RforProteomics/inst/doc/RProtVis.html). On
the left, we have a heatmap visualisation of a MS map and, in the
centre, a 3 dimensional representation of the same data. On the right,
2 MS1 spectra in blue and the set of interleaves 10 MS2 spectra.

```{r msmap1, message=FALSE, fig.width=15, echo=TRUE, fig.cap = "Plotting MS maps along retention time, MZ range and intensity."}
msn <- readMSData(mzf, mode = "onDisk")

## a set of spectra of interest: MS1 spectra eluted
## between 30 and 35 minutes retention time
ms1 <- which(msLevel(msn) == 1)
rtsel <- rtime(msn)[ms1] / 60 > 30 &
    rtime(msn)[ms1] / 60 < 35

## the MS map
M <- MSmap(msn, scans = ms1[rtsel],
           lowMz = 521, highMz = 523,
           resMz = .005)
## custom colours
ff <- colorRampPalette(c("yellow", "steelblue"))
lattice::trellis.par.set(regions=list(col=ff(100)))
## heatmap
m1 <- plot(M, aspect = 1, allTicks = FALSE)

## set 0s to NA for better visualisation
M@map[msMap(M) == 0] <- NA
m2 <- plot3D(M, rgl = FALSE)

## MS map with MS1 and MS2 spectra
i <- ms1[which(rtsel)][1] ## 1st MS1
j <- ms1[which(rtsel)][2] ## 2nd MS1
## All MS 1 and 2 spectra between i and j
M2 <- MSmap(msn, i:j, 100, 1000, 1)
m3 <- plot3D(M2)

gridExtra::grid.arrange(m1, m2, m3, ncol = 3)
```

Below, we have animations build from extracting successive slices as above.

![MS animation 1](./Figures/msanim1.gif)
![MS animation 2](./Figures/msanim2.gif)

# Identification data

## Identification data.frame

Let's use the identification from from `msdata`:

```{r mzrvsid, eval = TRUE}
idf <- msdata::ident(full.names = TRUE)
basename(idf)
```

The easiest way to read identification data in `mzIdentML` (often
abbreviated with `mzid`) into R is to read it with `readMzIdData`,
that will parse it, process it, and return a `data.frame`:

```{r readid}
iddf <- readMzIdData(idf)
head(iddf)
```

When adding identification data with the `addIdentificationData`
function as shown above, the data is first read with `readMzIdData`,
and is then cleaned up:

- only PSMs matching the regular (non-decoy) database are retained;
- PSMs or rank greater than 1 are discarded;
- only proteotypic peptides are kept, i.e. those that match to a
  unique peptide.

```{r idfilt}
## at this stage, we still have all the PSMs
table(iddf$isDecoy)
table(iddf$rank)
```

> **Exercise** This behaviour can be replicates with the
> `filterIdentificationDataFrame` function. Try it out for yourself.

<details>
```{r filtid}
iddf2 <- filterIdentificationDataFrame(iddf)
table(iddf2$isDecoy)
table(iddf2$rank)
```
</details>

> **Exercise** The standard `r CRANpkg("tidyverse")` tools are fit for
> data wrangling with identification data. Using the above
> identification dataframe, calculate the length of each peptide (you
> can use `nchar` with the peptide sequence `sequence`) and the number
> of peptides for each protein (defined as
> `DatabaseDescription`). Plot the length of the proteins against
> their respective number of peptides. Optionally, stratify the plot
> by the peptide e-value score (`MS.GF.EValue`) using for example
> `cut` to define bins.

<details>
```{r answid1, fig.cap="Identifcation data wrangling 1"}
suppressPackageStartupMessages(library("dplyr"))
iddf2 <- as_tibble(iddf2) %>%
    mutate(peplen = nchar(sequence))
npeps <- iddf2 %>%
    group_by(DatabaseDescription) %>%
    tally
iddf2 <- full_join(iddf2, npeps)

library("ggplot2")
ggplot(iddf2, aes(x = n, y = DBseqLength)) + geom_point()
```

```{r answid2, fig.cap="Identifcation data wrangling 2"}
iddf2$evalBins <- cut(iddf2$MS.GF.EValue, summary(iddf2$MS.GF.EValue))
ggplot(iddf2, aes(x = n, y = DBseqLength, color = peplen)) +
    geom_point() +
    facet_wrap(~ evalBins)
```
</details>

## Low level access to id data

<div class="boxed blue">Devel</div>

Along the lines of what is available for raw data, the parsing of this
XML-based format comes from `mzR`. A file handle to `mzIdentML` files
can be created with the `openIDfile` function. As for raw data, the
underlying C/C++ code comes from the
[proteowizard](http://proteowizard.sourceforge.net/).

```{r openid}
library("mzR")
id1 <- openIDfile(idf)
id1
```

Various data can be extracted from the identification object. The
peptide spectrum matches (PSMs) and the identification scores can be
accessed as a data.frame with `psms` and `score` respectively.

```{r psms}
softwareInfo(id1)
enzymes(id1)
fid1 <- mzR::psms(id1)
head(fid1)
```

```{r iscores}
sc1 <- mzR::score(id1)
head(sc1)
```

The `r Biocpkg("mzID")` package, has similar functionality to parse
identification files, and was the first one to provide such
capabilities in R. The main difference with `r Biocpkg("mzR")` is that
is parses the files using the `r CRANpkg("XML")`package and reads the
whole data into memory rather than relying on proteowizard, and is
slower.

## MS/MS database search

While searches are generally performed using third-party software
independently of R or can be started from R using a `system` call, the
`r Biocpkg("MSGFplus")` package enables to perform a search using the
MSGF+ engine, as illustrated below.

We search the `r basename(mzf)` file against the fasta file from
`PXD000001` using `MSGFplus`.

We first download the fasta files from ProteomeXchange:

<div class="boxed yellow">On-line</div>

```{r ex_getfas, cache=TRUE}
fas <- pxget(px, "erwinia_carotovora.fasta")
basename(fas)
```

Below, we setup and run the
search^[In the `runMSGF` call, the memory allocated to the java virtual machine is limited to 1GB. In general, there is no need to specify this argument, unless you experience an error regarding the *maximum heap size*.].

```{r ex_msgfplus, message=FALSE, cache=TRUE}
library("MSGFplus")
msgfpar <- msgfPar(database = fas,
                   instrument = 'HighRes',
                   tda = TRUE,
                   enzyme = 'Trypsin',
                   protocol = 'iTRAQ')
idres <- runMSGF(msgfpar, mzf, memory=1000)
idres
## identification file (needed below)
basename(mzID::files(idres)$id)
```

A graphical interface to perform the search the data and explore the
results is also available:

```{r msgfgui, eval=FALSE}
library("MSGFgui")
MSGFgui()
```

![The `r Biocpkg("MSGFgui")` interface](./Figures/MSGFgui.png)

The `r Biocpkg("rTANDEM")` package can be used to perform a search
with *XTandem* software.

## Analysing search results

The `r Biocpkg("MSnID")` package can be used for post-search filtering
of MS/MS identifications. One starts with the construction of an
`MSnID` object that is populated with identification results that can
be imported from a `data.frame` or from `mzIdenML` files. Here, we
will use the example identification data provided with the package.

```{r idf}
mzids <- system.file("extdata", "c_elegans.mzid.gz", package="MSnID")
basename(mzids)
```

We start by loading the package, initialising the `MSnID` object, and
add the identification result from our `mzid` file (there could of
course be more that one).

```{r msnid1}
library("MSnID")
msnid <- MSnID(".")
msnid <- read_mzIDs(msnid, mzids)
show(msnid)
```

Printing the `MSnID` object returns some basic information such as

* Working directory.
* Number of spectrum files used to generate data.
* Number of peptide-to-spectrum matches and corresponding FDR.
* Number of unique peptide sequences and corresponding FDR.
* Number of unique proteins or amino acid sequence accessions and corresponding FDR.


The package then enables to define, optimise and apply filtering based
for example on missed cleavages, identification scores, precursor mass
errors, etc. and assess PSM, peptide and protein FDR levels. To
properly function, it expects to have access to the following data

```{r msnidcols, echo=FALSE}
sort(MSnID:::.mustBeColumns)
```

which are indeed present in our data:

```{r msnidnames}
names(msnid)
```

Here, we summarise a few steps and redirect the reader to the
package's vignette for more details:


### Analysis of peptide sequences {-}

Cleaning irregular cleavages at the termini of the peptides and
missing cleavage site within the peptide sequences. The following two
function call create the new `numMisCleavages` and `numIrrCleabages`
columns in the `MSnID` object

```{r msnidtermini}
msnid <- assess_termini(msnid, validCleavagePattern="[KR]\\.[^P]")
msnid <- assess_missed_cleavages(msnid, missedCleavagePattern="[KR](?=[^P$])")
```

### Trimming the data {-}

Now, we can use the `apply_filter` function to effectively apply
filters. The strings passed to the function represent expressions that
will be evaluated, this keeping only PSMs that have 0 irregular
cleavages and 2 or less missed cleavages.

```{r msnidtrim}
msnid <- apply_filter(msnid, "numIrregCleavages == 0")
msnid <- apply_filter(msnid, "numMissCleavages <= 2")
show(msnid)
```

### Parent ion mass errors {-}

Using `"calculatedMassToCharge"` and `"experimentalMassToCharge"`, the
`mass_measurement_error` function calculates the parent ion mass
measurement error in parts per million.

```{r msnidppm1}
summary(mass_measurement_error(msnid))
```

We then filter any matches that do not fit the +/- 20 ppm tolerance

```{r msnidppm2}
msnid <- apply_filter(msnid, "abs(mass_measurement_error(msnid)) < 20")
summary(mass_measurement_error(msnid))
```

### Filtering criteria {-}

Filtering of the identification data will rely on

* -log10 transformed MS-GF+ Spectrum E-value, reflecting the goodness
  of match experimental and theoretical fragmentation patterns

```{r filt1}
msnid$msmsScore <- -log10(msnid$`MS-GF:SpecEValue`)
```

* the absolute mass measurement error (in ppm units) of the parent ion

```{r filt2}
msnid$absParentMassErrorPPM <- abs(mass_measurement_error(msnid))
```

MS2 filters are handled by a special `MSnIDFilter` class objects, where
individual filters are set by name (that is present in `names(msnid)`)
and comparison operator (>, <, = , ...)  defining if we should retain
hits with higher or lower given the threshold and finally the
threshold value itself.

```{r filt3}
filtObj <- MSnIDFilter(msnid)
filtObj$absParentMassErrorPPM <- list(comparison="<", threshold=10.0)
filtObj$msmsScore <- list(comparison=">", threshold=10.0)
show(filtObj)
```

We can then evaluate the filter on the identification data object,
which return the false discovery rate and number of retained
identifications for the filtering criteria at hand.

```{r filt4}
evaluate_filter(msnid, filtObj)
```

### Filter optimisation {-}

Rather than setting filtering values by hand, as shown above, these
can be set automativally to meet a specific false discovery rate.

```{r optim1}
filtObj.grid <- optimize_filter(filtObj, msnid, fdr.max=0.01,
                                method="Grid", level="peptide",
                                n.iter=500)
show(filtObj.grid)
```

```{r optim2}
evaluate_filter(msnid, filtObj.grid)
```

Filters can eventually be applied (rather than just evaluated) using
the `apply_filter` function.

```{r optim3}
msnid <- apply_filter(msnid, filtObj.grid)
show(msnid)
```

And finally, identifications that matched decoy and contaminant
protein sequences are removed

```{r optim4}
msnid <- apply_filter(msnid, "isDecoy == FALSE")
msnid <- apply_filter(msnid, "!grepl('Contaminant',accession)")
show(msnid)
```

The resulting filtered identification data can be exported to a
`data.frame` or to a dedicated `MSnSet` data structure for
quantitative MS data, described below, and further processed and
analyses using appropriate statistical tests.

## Visualising identification data

Annotated spectra and comparing spectra.

```{r id1, message=FALSE, fig.width=15, message=FALSE, fig.cap = "Annotating and comparing MS2 spectra."}
par(mfrow = c(1, 2))
data(itraqdata)
itraqdata2 <- pickPeaks(itraqdata, verbose = FALSE) ## centroiding
s <- "SIGFEGDSIGR"
plot(itraqdata2[[14]], s, main = s)
plot(itraqdata2[[25]], itraqdata2[[28]], sequences = rep("IMIDLDGTENK", 2))
```

The annotation of spectra is obtained by simulating fragmentation of a
peptide and matching observed peaks to fragments:

```{r fag}
calculateFragments("SIGFEGDSIGR")
```

Visualising a pair of spectra means that we can access them, and that,
in addition to plotting, we can manipulate them and perform
computations. The two spectra corresponding to the `IMIDLDGTENK`
peptide, for example have
`r compareSpectra(itraqdata2[[25]], itraqdata2[[28]], fun = "common")`
common peaks, a correlation of
`r round(compareSpectra(itraqdata2[[25]], itraqdata2[[28]], fun = "cor"), 3)`
and a dot product of
`r round(compareSpectra(itraqdata2[[25]], itraqdata2[[28]], fun = "dotproduct"), 3)`
(see `?compareSpectra` for details).

> **Exercise** Use the `compareSpectra` function to compare spectra 25
>  and 28 plotted above, calculating the metrics mentioned
>  above. Don't forget to pick peaks from `itraqdata` first.

<details>
```{r compspex}
data(itraqdata)
itraqdata2 <- pickPeaks(itraqdata, verbose = FALSE)
compareSpectra(itraqdata2[[25]], itraqdata2[[28]], fun = "common")
compareSpectra(itraqdata2[[25]], itraqdata2[[28]], fun = "cor")
compareSpectra(itraqdata2[[25]], itraqdata2[[28]], fun = "dotproduct")
```
</details>

# Quantitative proteomics

There are a wide range of proteomics quantitation techniques that can
broadly be classified as labelled vs. label-free, depending whether
the features are labelled prior the MS acquisition and the MS level at
which quantitation is inferred, namely MS1 or MS2.

```{r quanttab, echo=FALSE, results='asis'}
qtb <- matrix(c("XIC", "Counting", "SILAC, 15N", "iTRAQ, TMT"),
              nrow = 2, ncol = 2)
dimnames(qtb) <- list(
    'MS level' = c("MS1", "MS2"),
    'Quantitation' = c("Label-free", "Labelled"))

knitr::kable(qtb)
```

In terms of raw data quantitation, most efforts have been devoted to
MS2-level quantitation. Label-free XIC quantitation has however been
addressed in the frame of metabolomics data processing by the
`r Biocpkg("xcms")` infrastructure.

Below is a list of suggested packages for some common proteomics
quantitation technologies:

* Isobaric tagging (iTRAQ and TMT): `r Biocpkg("MSnbase")` and `r Biocpkg("isobar")`.
* Label-free: `r Biocpkg("xcms")` (metabolomics).
* Counting: `r Biocpkg("MSnbase")` and `r Biocpkg("MSnID")` for
  peptide-spectrum matching confidence assessment.
* `r Githubpkg("vladpetyuk/N14N15")` for heavy Nitrogen-labelled data.

## The `MSnSet` class for quantitative data

Quantitative data is stored in a dedicated data structure called
`MSnSet`. The figure below gives a schematics of an `MSnSet` instance
and the relation between the assay data and the respective feature and
sample metadata, accessible respectively with the `exprs`, `fData` and
`pData` functions.

![The MSnSet structure](./Figures/msnset.png)


Storing quantitative data in an `MSnSet` quaranties that the feature
(peptides or proteins) and sample annotations are correctly aligned
with the quantitative data, i.e.

- there is a one-to-one match between the expression data rows and
  feature meta data rows;
- there is a one-to-one match between the expression data columns and
  sample meta data rows.

This correspondance is also guaranteed during all data processing and
manipulation.


## Isobaric tagging

An `MSnExp` is converted to an `MSnSet` by the `quantitation`
method. Below, we use the iTRAQ 4-plex isobaric tagging strategy
(defined by the `iTRAQ4` parameter; other tags are available: see
`?ReporterIons`) and the `max` method to calculate the use the maximum
of the reporter peak for quantitation.

```{r itraq4plot, fig.cap = "MS2 spectrum and it's iTRAQ4 reporter ions."}
plot(msexp[[1]], full=TRUE, reporters = iTRAQ4)
```

```{r quantitraq}
msset <- quantify(msexp, method = "max", reporters = iTRAQ4)
```

Below, we access the quantitative and metadata slots of the newly
created `MSnSet` object.


```{r msnsetslots1}
exprs(msset)
head(fData(msset))
pData(msset)
```

New columns can be added to the metadata slots.


```{r msnsetslots2}
pData(msset)$groups <- rep(c("Treat", "Cond"), each = 2)
pData(msset)
```

Another useful slot is `processingData`, accessed with
`processingData(.)`, that records all the processing that objects have
undergone since their creation.


```{r msnsetslots3}
processingData(msset)
```

## Spectral counting

Other MS2 quantitation methods available in `quantify` include the
(normalised) spectral index `SI` and (normalised) spectral abundance
factor `SAF` or simply a simple count
method^[The code below is for illustration only - it doesn't make much sense to perform any of these quantitations on such a multiplexed data].

```{r lfms2}
exprs(si <- quantify(msexp, method = "SIn"))
exprs(saf <- quantify(msexp, method = "NSAF"))
```

Note that spectra that have not been assigned any peptide (`NA`) or
that match non-unique peptides (`npsm > 1`) are discarded in the
counting process.


As shown above, the `r Biocpkg("MSnID")` package enables to explore
and assess the confidence of identification data using `mzid` files. A
subset of all peptide-spectrum matches, that pass a specific false
discovery rate threshold can them be converted to an `MSnSet`, where
the number of peptide occurrences are used to populate the assay data.

## Importing third-party quantitation data

### From `MzTab` files {-}

<div class="boxed yellow">On-line</div>

The Proteomics Standard Initiative (PSI) `mzTab` file format is aimed
at providing a simpler (than XML formats) and more accessible file
format to the wider community. It is composed of a key-value metadata
section and peptide/protein/small molecule tabular sections. These
data can be imported with the `readMzTabData`
function^[We specify version 0.9 (which generates the warning) to fit with the version of that file. For recent files, the `version` argument should be ignored to use the importer for the current file version 1.0.].


```{r mztab, cache=TRUE}
mztf <- pxget(px, "F063721.dat-mztab.txt")
(mzt <- readMzTabData(mztf, what = "PEP", version = "0.9"))
```

### From spreadsheets {-}

It is also possible to import arbitrary spreadsheets (such as those
exported by MaxQuant, ProteomeDiscoverer, ...) as `MSnSet` objects
into R with the `readMSnSet2` function. The main 2 arguments of the
function are (1) a text-based spreadsheet and (2) column names of
indices that identify the quantitation data. The latter can be queried
with the `getEcols` function.

```{r readmsnset2}
csv <- dir(system.file ("extdata" , package = "pRolocdata"),
           full.names = TRUE, pattern = "pr800866n_si_004-rep1.csv")
getEcols(csv, split = ",")
ecols <- 7:10
res <- readMSnSet2(csv, ecols)
head(exprs(res))
head(fData(res))
```

However, as we see below, we do not have any metadata about samples,
i.e. about the design of the experiment.

```{r respd}
pData(res)
```

This can be done manually, or by importing a csv file containing that
design. Below, we define two groups and two operators for the 4
samples of the `res` object created above:

```{r}
pData(res)$group <- rep(c("A", "B"), each = 2)
pData(res)$operator <- rep(1:2, 2)
pData(res)
```

Note that `pData(res)$` can be shortened with `res$`. This is also
valid when setting new metadata, as shown above.

```{r}
pData(res)$group
res$group
```

> **Exercise** Using `readMSnSet2`, load the following file that was
> part of the supplementary information of a manuscript.

```{r pdfile}
csvfile <- dir(system.file("extdata", package = "pRolocdata"),
               pattern = "hyperLOPIT-SIData-ms3-rep12-intersect.csv",
               full.names = TRUE)
basename(csvfile)
```

> You'll first need to identify which columns to use as expression
> data. In this case however, two rows are used as header, and you'll
> need to set `n` in `getEcols` to retrieve the appropriate one. There
> are 20 expresion columns annotated as TMT 10 plex reporter ion M/Z
> values (if you don't know these, you can find them out by looking at
> the `TMT10` reporter ion object). You can now use `readMSnSet2`,
> remembering to skip 1 line and, optionally, use the first column as
> feature names (see the `fnames` argument). What are the number of
> features and samples in the data?


<details>
```{r solreadmsnset}
getEcols(csvfile, split = ",", n = 2)
msn <- readMSnSet2(csvfile, ecol = 8:27, fnames = 1, skip = 1)
dim(msn)
```
</details>

> **Exercise** Add the following experimental design to the `MSnSet`
> created above. The 10 first samples originate from batch A, and the
> 10 following from batch B. Sameple 1 to 5 and 11 to 15 belong to the
> control group, and the others to the condition group. Even samples
> are female and odd samples are male.

<details>
```{r solreadmsnset2}
msn$batch <- rep(c("A", "B"), each = 10)
msn$group <- rep(rep(c("CTRL", "COND"), each = 5), 2)
msn$gender <- rep(c("M", "F"), 10)
```
</details>



# Data processing and analysis

## Raw data processing

For raw data processing look at `MSnbase`'s `clean`, `smooth`,
`pickPeaks`, `removePeaks` and `trimMz` for `MSnExp` and spectra
processing methods.

As an illustration, we show the `pickPeaks` function on the
`itraqdata` data. Centoiding transforms the distribution of M/Z values
measured for an ion (i.e. a set of M/Z and intensities, first figure
below) into a single M/Z and intensity pair of values (second figure
below).


```{r peakpicking, fig.keep = "last", fig.cap = "Peak picking: profile mode."}
library("ggplot2") ## for coord_cartesian
data(itraqdata)
plot(itraqdata[[10]], full = TRUE) +
    coord_cartesian(xlim = c(915, 925))
```

```{r peakpicking2, fig.keep = "last", fig.cap = "Peak picking: centroided."}
itraqdata2 <- pickPeaks(itraqdata)
plot(itraqdata2[[10]], full = TRUE) +
    coord_cartesian(xlim = c(915, 925))
```

The `r Biocpkg("MALDIquant")` and `r Biocpkg("xcms")` packages also
features a wide range of raw data processing methods on their own ad
hoc data instance types.

## Quantitative data processing and normalisation

### Isobaric purity correction {-}

Each different types of quantitative data will require their own
pre-processing and normalisation steps. Both `isobar` and `MSnbase`
allow to correct for isobaric tag impurities normalise the
quantitative data.

```{r pure}
data(itraqdata)
qnt <- quantify(itraqdata, method = "trap", reporters = iTRAQ4)
impurities <- matrix(c(0.929, 0.059, 0.002, 0.000,
                       0.020, 0.923, 0.056, 0.001,
                       0.000, 0.030, 0.924, 0.045,
                       0.000, 0.001, 0.040, 0.923),
                     nrow = 4, byrow = TRUE)
## or, using makeImpuritiesMatrix()
## impurities <- makeImpuritiesMatrix(4)
qnt <- purityCorrect(qnt, impurities)
processingData(qnt)
```

### Normalisation {-}

Various normalisation methods can be applied the `MSnSet` instances
using the `normalise` method: variance stabilisation (`vsn`), quantile
(`quantiles`), median or mean centring (`center.media` or
`center.mean`), ...

```{r norm}
qnt <- normalise(qnt, "quantiles")
processingData(qnt)
```

### Combining features {-}

The `combineFeatures` method combines spectra/peptides quantitation
values into protein data. The grouping is defined by the `groupBy`
parameter, which is generally taken from the feature metadata (protein
accessions, for example).

```{r comb}
prt <- combineFeatures(qnt, fcol = "ProteinDescription", fun = "median")
processingData(prt)
```

### Missing values {-}

Finally, proteomics data analysis is generally hampered by missing
values. Missing data imputation is a sensitive operation whose success
will be guided by many factors, such as degree and (non-)random nature
of the missingness.

Below, we load an `MSnSet` with missing values, count the number
missing and non-missing values.

```{r impute0}
data(naset)
table(is.na(naset))
```

The `naplot` figure will reorder cells within the data matrix so that
the experiments and features with many missing values will be grouped
towards the top and right of the heatmap, and barplots at the top and
right summarise the number of missing values in the respective samples
(column) and rows (rows).

```{r naplot, fig.cap = "Overview of missing values."}
naplot(naset)
```

The importance of missing values in a dataset will depend on the
quantitation technology employed. Label-free quantitation in
particular can suffer from a very high number of missing values.

Missing value in `MSnSet` instances can be filtered out with the
`filterNA` functions. By default, it removes features that contain at
least `NA` value.

```{r filterNA}
## remove features with missing values
tmp <- filterNA(naset)
processingData(tmp)
```


It is of course possible to impute missing values (`?impute`). This is
however not a straightforward thing, as is likely to dramatically fail
when a high proportion of data is missing (10s of
%)^[Note that when using `r Biocpkg("limma")` for instance, downstream analyses can handle missing values. Still, it is recommended to explore missingness as part of the exploratory data analysis.]. But
also, there are two types of mechanisms resulting in missing values in
LC/MSMS experiments.

* Missing values resulting from absence of detection of a feature,
  despite ions being present at detectable concentrations.  For
  example in the case of ion suppression or as a result from the
  stochastic, data-dependent nature of the MS acquisition
  method. These missing value are expected to be randomly distributed
  in the data and are defined as **missing at random** (MAR) or
  **missing completely at random** (MCAR).

* Biologically relevant missing values, resulting from the *absence*
  or the low abundance of ions (below the limit of detection of the
  instrument). These missing values are not expected to be randomly
  distributed in the data and are defined as **missing not at random**
  (MNAR).

```{r naheatmap, echo=FALSE, fig.cap="Random and non-random missing values."}
x <- impute(naset, "zero")
exprs(x)[exprs(x) != 0] <- 1
gplots::heatmap.2(exprs(x), col = c("lightgray", "black"),
                  scale = "none", dendrogram = "none",
                  trace = "none", keysize = 0.5, key = FALSE,
                  RowSideColors = ifelse(fData(x)$randna, "orange", "brown"),
                  ColSideColors = rep(c("steelblue", "darkolivegreen"), each = 8))
```

Different imputation methods are more appropriate to different classes
of missing values (as documented in this
[paper](http://pubs.acs.org/doi/abs/10.1021/acs.jproteome.5b00981)). Values
missing at random, and those missing not at random should be imputed
with different methods.

![Root-mean-square error (RMSE) observations standard deviation ratio (RSR), KNN and MinDet imputation. Lower (blue) is better. (See [here](http://pubs.acs.org/doi/abs/10.1021/acs.jproteome.5b00981) for details)](./Figures/imp-sim.png)

Generally, it is recommended to use **hot deck** methods (nearest
neighbour (**left**), maximum likelihood, ...) when data are missing
at random.Conversely, MNAR features should ideally be imputed with a
**left-censor** (minimum value (**right**), but not zero, ...) method.


```{r impute}
## impute missing values using knn imputation
tmp <- impute(naset, method = "knn")
processingData(tmp)
```

There are various methods to perform data imputation, as described in
`?impute`. The `r CRANpkg("imp4p")` package contains additional
functionality, including some to estimate the randomness of missing
data.


> **Exercise** Following the example above, apply a mixed imputation,
> using knn for data missing at random and the deterministic minumum
> left-cencored imputation for data missing no at random.


<details>
```{r naex1, message = FALSE}
impute(naset, "mixed",
       randna = fData(naset)$randna,
       mar = "knn", mnar = "MinDet")
```
</details>

> **Exercise** When assessing missing data imputation methods, such as
> in [Lazar et
> al. (2016)](https://pubs.acs.org/doi/abs/10.1021/acs.jproteome.5b00981),
> one often replaces values with missing data, imputes these with a
> method of choice, then quantifies the difference between original
> (expected) and observed (imputed) values. Here, using the `naset`
> data, use this strategy to assess the difference between knn and
> Bayesian PCA imputation.

<details>
```{r naex2, cache = TRUE}
imp1 <- impute(naset, method = "knn")
imp2 <- impute(naset, method = "bpca")
summary(abs(exprs(imp1)[is.na(naset)] - exprs(imp2)[is.na(naset)]))
summary(as.numeric(na.omit(exprs(naset))))
```
</details>

> **Exercise** When assessing the impact of missing value imputation
> on real data, one can't use the strategy above. Another useful
> approach is to assess the impact of the imputation method on the
> distribution of the quantitative data. For instance, here is the
> intensity distribution of the `naset` data. Verify the effect of
> applying `knn`, `zero`, `MinDet` and `bpca` on this distribution.

```{r nasetdist, fig.cap = "Intensity disctribution of the `naset` data."}
plot(density(na.omit(exprs(naset))))
```

<details>
```{r naex3, cache = TRUE}
cls <- c("black", "red", "blue", "steelblue", "orange")
plot(density(na.omit(exprs(naset))), col = cls[1])
lines(density(exprs(impute(naset, method = "knn"))), col = cls[2])
lines(density(exprs(impute(naset, method = "zero"))), col = cls[3])
lines(density(exprs(impute(naset, method = "MinDet"))), col = cls[4])
lines(density(exprs(impute(naset, method = "bpca"))), col = cls[5])
legend("topright", legend = c("orig", "knn", "zero", "MinDet", "bpca"),
       col = cls, lwd = 2, bty = "n")
```
</details>

## Some notes on data analysis and manipulation

The `tidyverse` syntax has proved to be versatile and very useful for
generic data analysis, i.e. analysis of data stored in
dataframes. While it is possible to convert dedicated data containers
into dataframes, this leads to loosing data integrity checks and
access to dedicated omics data processing functions.

The `r BiocStyle::Githubpkg("tidies")` enables to use typical dplyr
functions directly on `MSnSet` data structures. See the vignette at
[http://lgatto.github.io/tidies/](http://lgatto.github.io/tidies/) for
details and examples.

```{r tidies1, warning = FALSE}
library("tidies")
data(msnset)
## Some test sample groups
msnset$group <- c("A", "A", "B", "B")
```

```{r tidies2}
msnset %>%
    dplyr::select(starts_with("Protein")) %>%
    fvarLabels
```

```{r tidies3}
msnset %>%
    filter(ProteinAccession == "ENO") %>%
    exprs
```

```{r tides4}
msnset %>% group_by(ProteinAccession) %>%
    summarise(median(exprs, na.rm = TRUE)) %>%
    exprs %>%
    head
msnset %>% group_by(group) %>%
    summarise(mean(exprs, na.rm = TRUE)) %>%
    exprs %>%
    head
msnset %>%
    group_by(charge) %>%
    summarise(mean(exprs)) %>%
    group_by(group) %>%
    summarise(max(exprs, na.rm = TRUE)) %>%
    exprs
```

```{r tidies5}
msnset %>%
    filterNA() %>%
    combineFeatures(method = "median", fcol = "ProteinAccession") %>%
    group_by(group) %>%
    summarise(mean(exprs)) %>%
    normalise(method = "quantiles") %>%
    filter(ProteinAccession %in% c('ENO', 'BSA')) %>%
    exprs
```

# Statistical analysis

R in general and Bioconductor in particular are well suited for the
statistical analysis of data of quantitative proteomics data. Several
packages provide dedicated resources for proteomics data:

- `r Biocpkg("MSstats")` and `r Biocpkg("MSstatsTMT")`: A set of tools
  for statistical relative protein significanceanalysis in Data dependent
  (DDA), SRM, Data independent acquisition (DIA) and TMT experiments.

- `r Biocpkg("msmsTests")`: Statistical tests for label-free LC-MS/MS
  data by spectral counts, to discover differentially expressed
  proteins between two biological conditions. Three tests are
  available: Poisson GLM regression, quasi-likelihood GLM regression,
  and the negative binomial of the `r Biocpkg("edgeR")`
  package. All can be readily applied on `MSnSet` instances produced,
  for example by `MSnID`.

- `r Biocpkg("isobar")` also provides dedicated infrastructure for the
  statistical analysis of isobaric data.

- `r Biocpkg("DEP")` provides an integrated analysis workflow for the
  analysis of mass spectrometry proteomics data for differential
  protein expression or differential enrichment.

Others, while not specfic to proteomics, are also recommended, such as
the `r Biocpkg("limma")` package. When analysing spectral counting
data, methods for high throughput sequencing data are
applicable. Below, we illustrate how to apply a typical `edgeR` test
to count data using the `msms.edgeR` function from the `msmsTests`
package.

The data is illustrated below (we will see later how to generate such
plots), showing two experimental conditions (red and blue points)
processed as two batches (solid and empty points).

```{r msmspca, echo = FALSE, message = FALSE}
library(msmsTests)
data(msms.dataset)
e <- msms.dataset[rowSums(exprs(msms.dataset)) > 0, ]
e <- e[!grepl("-R$", featureNames(e)), ]
plot2D(t(e), fcol = "treat", fpch = "batch")
```

nWe first pre-process to remove features containing only 0s and
entries from the reverse database (ending with '-R') (see also the
`pp.msms.data` function).

```{r msmspp}
library(msmsTests)
data(msms.dataset)
e <- msms.dataset[rowSums(exprs(msms.dataset)) > 0, ]
e <- e[!grepl("-R$", featureNames(e)), ]
pData(e)
```

```{r msmsedger}
null.f <- "y~batch"
alt.f <- "y~treat+batch"
div <- apply(exprs(e), 2, sum)
res <- msms.edgeR(e, alt.f, null.f, div = div)
head(res)
```

It is best to store the results directly with the quantitative
data. Below, we first check that the results rownames match the
feature names and then add it to the feature metadata.

```{r cbindfd}
identical(rownames(res), featureNames(e))
fData(e) <- cbind(fData(e), res)
```

And we conclude with a volcano plot of the results of the test.

```{r volc, fig.cap = "Volcano plot."}
plot(fData(e)$LogFC, -log10(fData(e)$p.value))
```

# Machine learning

There are numerous packages for machine learing in R, many with
specific omics applications and use cases in mind. An excellent
general package is `r CRANpkg("mlr")` that provides a unified
interface to many methods. For a general hands-on introduction, [*An
introduction to machine learning with R*](http://bit.ly/intromlr), as
well as many other freely available documents are available.

The `r Biocpkg("MLInterfaces")` package provides a unified interface
to a wide range of machine learning algorithms. Initially developed
for microarray and `ExpressionSet` instances, the `r
Biocpkg("pRoloc")` package enables application of these algorithms to
`MSnSet` data. We will also demonstrate some specific functions of the
`r Biocpkg("pRoloc")` package.

## Dimensionality reduction

Dimensionality reduction is very frequently used to summarise
high-dimensional data. Below we will use principal component analysis
(PCA), but other methods can be applied. Below, we will use the
`plot2D` function from the `r Biocpkg("pRoloc")`
package^[While originally developed for the analysis of spatial/organelle proteomics data in mind, it is applicable many use cases.],
that will extract the expression values in the assay data, perform
dimensionality reduction, an produce the scatter plot.

Let's first use `plot2D` to visualise the pattern in 20 protein
quantitation values (initial 20 dimensional data). Here, we use an
example from spatial proteomics, where the quantitative protein
profiles reflect the proteins sub-cellular localisation (from
[Christoforou *et al*, 2016](https://www.nature.com/articles/ncomms9992),
see also
[Breckels *et al*, 2016](https://f1000research.com/articles/5-2926/)
for more data analysis background). We will use the known localisation
of some proteins (marker proteins) to annotate the plot using the
`fcol` argument, that indicates which feature variable (i.e. column un
the feature meta-data) to use.

```{r plot2D1, fig.cap="PCA plot for protein sub-cellular localisation."}
library("pRoloc")
library("pRolocdata")
data(hyperLOPIT2015)
plot2D(hyperLOPIT2015, fcol = "markers")
addLegend(hyperLOPIT2015, fcol = "markers", cex = .7)
```

> **Exercise** The results of a clasification analysis (see below) are
> available in `svm.classification` feature variable. Repeat the PCA
> plot above, colouring the proints using this variable.

<details>
```{r plot2Dex, fig.cap = "Plotting all the classification results."}
plot2D(hyperLOPIT2015, fcol = "svm.classification")
```
</details>

In other cases, we want to visualise the relation of samples. `plot2D`
uses the rows of the data to perform dimensionality reduction. To use
the columns, we just need to transpose the `MSnSet`. By doing so, the
`pData` becomes the `fData` and vice versa.

Let's use a time-course experiment on stem cells
([Mulvey *et al.* 2015](https://www.ncbi.nlm.nih.gov/pubmed/26059426)).
Below, we use the `times` (time points) variable to set colours.

```{r plot2S2, fig.cap="PCA plots for sample in a time-course experiment."}
data(mulvey2015)
head(pData(mulvey2015))
plot2D(t(mulvey2015),  fcol = "times", cex = 2)
addLegend(t(mulvey2015),  fcol = "times")
```

> **Exercise** The `plot2D` function can use two feature variables to
> set colours with the `fcol` argument (as above) and point characters
> with the `fpch` argument. Use the latter to also highlight the
> replicate numbers `rep`.


<details>
```{r plot2Dex2, fig.cap = "Using colours and point characters to annotated the plot with `plot2D`."}
plot2D(t(mulvey2015),  fcol = "times", fpch = "rep", cex = 2)
```
</details>

## Classification

Classification is performed in two steps. First, an adequate model and
its parameters are learned from labelled training data, then that
model is applied on new, unlabelled data.

We are going to apply this strategy to repeat the protein sub-cellular
classification analysis of the `hyperLOPIT2015` data above using a *k*
nearest neighbour classifier, which is generally used as a baseline
method. In the interest of time, we will only repeat the optimisation
step 10 times, even though 100 would be recommended. For details on
this procedure, please see the [main `pRoloc`
vignette](https://lgatto.github.io/pRoloc/articles/v01-pRoloc-tutorial.html].

```{r knnopt, cache = TRUE, warning = FALSE}
p <- knnOptimisation(hyperLOPIT2015, time = 10, verbose = FALSE)
p
```

We can now apply out best model (here *k* = 3) to out dataset, which
will add feature variables with the classification results (`knn`) and
scores (`knn.scores`).

```{r knnclass}
hyperLOPIT2015 <- knnClassification(hyperLOPIT2015, p)
fvarLabels(hyperLOPIT2015)
```

> **Exercise** Once you have performed the kNN classification as
> illustrated above, visualise your results on a PCA plot.

<details>
```{r knnex, eval = FALSE}
plot2D(hyperLOPIT2015, fcol = "knn")
```
</details>

Below, we show how to use `r Biocpkg("MLInterfaces")` to perform a
classification analysis using *k* nearest neighbours.

```{r ml}
library("MLInterfaces")
library("pRolocdata")
data(dunkley2006)
traininds <- which(fData(dunkley2006)$markers != "unknown")
ans <- MLearn(markers ~ ., data = t(dunkley2006), knnI(k = 5), traininds)
ans
```

## Clustering

To illustrate how to apply clustering in the frame of what we have
seen so far, we are going to use k-means clustering on the spatial
proteomics data above, visually comparing the clusters obtains with
the results of the classification results (in the `svm.classification`
feature variable).

We are (1) going to perform k-means setting the number of expected
clusters equal to the number of annotations, (2) store clustering
results as a new feature variable, and then (3) visualise the results
next to each other on two PCA plots.

We can use the `kmeans` function, passing the quantiative proteomics
data and the number of anticipated clusters as input:

```{r cl1}
## number of sub-cellular niches
n <- length(getMarkerClasses(hyperLOPIT2015))
cl <- kmeans(exprs(hyperLOPIT2015), n)
table(cl$cluster)
```

We can now add these results to our `MSnSet`:

```{r cl2}
fData(hyperLOPIT2015)$cluster <- cl$cluster
```

And now visualise the classification and clustering results side by
side:

```{r cl3, fig.width = 15, fig.cap = "PCA plot with the classification and clustering results." }
setStockcol(paste0(getStockcol(), 40))
par(mfrow = c(1, 2))
plot2D(hyperLOPIT2015, fcol = "svm.classification")
plot2D(hyperLOPIT2015, fcol = "cluster")
```

A wide range of clustering algorithms are available in
`r Biocpkg("MLInterfaces")`, as described in the `?MLearn`
documentation page, used below. Below, we show how to use it to
perform a k-means clustering.

```{r clust, fig.cap = "Kmeans clustering using `r Biocpkg('MLInterfaces')` with an `MSnSet` object."}
kcl <- MLearn( ~ ., data = dunkley2006, kmeansI, centers = 12)
kcl
plot(kcl, exprs(dunkley2006))
```

# Annotation

## The `rols` package

```{r nont, echo=FALSE, cache=TRUE}
library("rols")
onts <- Ontologies()
nont <- length(onts)
```

All the
[Bioconductor annotation infrastructure](http://bioconductor.org/help/workflows/annotation/Annotation_Resources/),
such as `r Biocpkg("biomaRt")`, `r Biocannopkg("GO.db")`,
organism specific annotations, ... are directly relevant to the
analysis of proteomics data. A total of `r nont` ontologies, including
some proteomics-centred annotations such as the PSI Mass Spectrometry
Ontology, Molecular Interaction (PSI MI 2.5) or Protein Modifications
are available through the `r Biocpkg("rols")`


```{r rols}
library("rols")
res <- OlsSearch(q = "ESI", ontology = "MS", exact = TRUE)
res
```

There is a single exact match (default is to retrieve 20 results),
that can be retrieved and coerced to a `Terms` or `data.frame` object
with

```{r rols2}
res <- olsSearch(res)
as(res, "Terms")
as(res, "data.frame")
```

## The Human Protein Atlas

Data from the [Human Protein Atlas](http://www.proteinatlas.org/) is
available via the `r Biocpkg("hpar")` package. Below, we are going to
illustrate how to use it with a usec ase retrieving sub-cellular
information for a protein, and contrast it with data from the
`r Biocpkg("GO.db")` package.

More HPA data are available, as documented in the package manual at
`?hpar`.

Let's compare the subcellular localisation annotation obtained from
the HPA subcellular location data set and the information available in
the Bioconductor annotation packages.

```{r uc-hpar}
library("hpar")
id <- "ENSG00000001460"
getHpa(id, "hpaSubcellularLoc")
```

Below, we first extract all cellular component GO terms available for
`id` from the `r Biocannopkg("org.Hs.eg.db")` human annotation and
then retrieve their term definitions using the `r Biocannopkg("GO.db")`
database.

```{r uc-db, message = FALSE}
library("org.Hs.eg.db")
library("GO.db")
ans <- AnnotationDbi::select(org.Hs.eg.db, keys = id,
                             columns = c("ENSEMBL", "GO", "ONTOLOGY"),
                             keytype = "ENSEMBL")
ans <- ans[ans$ONTOLOGY == "CC", ]
ans
sapply(as.list(GOTERM[ans$GO]), slot, "Term")
```


## The `ensembldb` package


The`r Biocannopkg("ensembldb")` allows to query and filter the data from ENSEMBL and integrates
smoothly with general Bioconductor infrastructure. Below are a couple
of illustrative examples, and more are available in the package
vignettes.


Below, we initialise the human database:

```{r ensdb}
library("ensembldb")
library("EnsDb.Hsapiens.v86")
edb <- EnsDb.Hsapiens.v86
edb
```

Here are the tables and columns available for that database:

```{r dbtabs}
listTables(edb)
```

### Fetch protein annotation for genes and transcripts {-}

Protein annotations for (protein coding) transcripts can be retrieved
by simply adding the desired annotation columns to the `columns` parameter.

```{r edbfetch}
## Get protein information for ZBTB16 transcripts
txs <- transcripts(edb, filter = GeneNameFilter("ZBTB16"),
                   columns = c("protein_id", "uniprot_id", "tx_biotype"))
txs
```

### Retrieve proteins from the database {-}

Below, we download the protein sequences for the *ZBTB16* gene.

```{r edbseq}
prts <- proteins(edb, filter = GeneNameFilter("ZBTB16"),
                 return.type = "AAStringSet")
prts
```

We can also get the associated meta-data with the `mcols` function.

```{r edbmcols}
mcols(prts)
```

# More information

## References and resources {-}

* [Visualisation of proteomics data using R and Bioconductor](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4510819/)
* [Using R and Bioconductor for proteomics data analysis](http://arxiv.org/pdf/1305.6559v1.pdf)
* `RforProteomics`: http://bioconductor.org/packages/RforProteomics

## Other relevant packages/pipelines {-}

- Analysis of post translational modification with `r Biocpkg("isobar")`.
- Processing and analysis or isobaric tagging mass spectrometry with
  `r Biocpkg("isobar")` and `r Biocpkg("MSnbase")`.
- Analysis of spatial proteomics data and, more generally, supervised,
  semi-supervised learning, and
  [transfer learning](https://www.ncbi.nlm.nih.gov/pubmed/23523639)
  using the `r Biocpkg("pRoloc")` package.
- Analysis of MALDI data with the `r Biocpkg("MALDIquant")` package.
- Access to the Proteomics Standard Initiative Common QUery InterfaCe
  with the `r Biocpkg("PSICQUIC")` package.
- `r Biocpkg("Cardinal")`: A mass spectrometry imaging toolbox for
  statistical analysis.
- `r Biocpkg("MSnID")`: Utilities for Exploration and Assessment of
  Confidence of LC-MSn Proteomics Identifications.
- `r CRANpkg("protViz") `: Visualising and Analysing Mass Spectrometry
  Related Data in Proteomics
- `r CRANpkg("aLFQ")`: Estimating Absolute Protein Quantities from
  Label-Free LC-MS/MS Proteomics Data.
- `r CRANpkg("protiq")`: Protein (identification and) quantification
  based on peptide evidence.
- `r Biocpkg("MSstats")`: Protein Significance Analysis in DDA, SRM
  and DIA for Label-free or Label-based Proteomics Experiments


### Data Independent Acquisition {-}

- Analysis of label-free data from a Synapt G2 (including ion
  mobility) with `r Biocpkg("synapter")`.
- `r Biocpkg("SWATH2stats")`: Transform and Filter SWATH Data for
  Statistical Packages and
- `r Biocpkg("specL")`: Prepare Peptide Spectrum Matches for Use in
  Targeted Proteomics
- `r Biocpkg("SwathXtend")`: SWATH extended library generation and
  statistical data analysis

## More questions {-}

After the workshop, the best place to ask questions about MS-based
proteomics and relevant Bioconductor package is the Bioconductor
[support forum](https://support.bioconductor.org/). Tagging you
question with *Proteomics* or specific package names will alert the
respective maintainers.

# Session Information

```{r maxprint, echo=FALSE}
options("max.print" = 1e3)
```

```{r si}
sessionInfo()
```
